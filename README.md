# NYC Taxi Big Data Pipeline

Pipeline completo de Big Data para anÃ¡lisis de viajes de taxi de Nueva York con procesamiento en tiempo real (streaming) y por lotes (batch) distribuido en AWS EC2.

## ğŸš€ Quick Start - Starting the Cluster

### Recommended Method: Interactive Startup

**Use `quick-start.sh` for the best experience:**

```bash
./quick-start.sh
```

This interactive script will:
- âœ… Verify SSH key
- âœ… Configure cluster IPs (saves to `.cluster-ips` for other scripts)
- âœ… Test connectivity
- âœ… Verify /etc/hosts
- âœ… Start all services in correct order
- âœ… Provide next steps

**Prerequisites:**
- EC2 instances are running
- SSH key `bigd-key.pem` is available (or path to your key)
- Know your current instance IPs

**Time: ~3-5 minutes** to start all services

### Alternative Methods:

```bash
# Direct startup (uses saved IPs from .cluster-ips)
./infrastructure/scripts/start-cluster.sh

# Step-by-step manual process
# See: docs/guides/START_CLUSTER_CHECKLIST.md
```

**Important:** Always use `quick-start.sh` first to configure IPs. Other scripts will automatically use the saved configuration.

---

## DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline de Big Data end-to-end que procesa datos histÃ³ricos de taxis de NYC simulando un entorno de producciÃ³n en tiempo real. Incluye:

- **Ingesta de datos**: Data producer con replay acelerado
- **Streaming processing**: Apache Flink para mÃ©tricas en tiempo real
- **Batch processing**: Apache Spark para anÃ¡lisis histÃ³ricos
- **Storage**: HDFS, PostgreSQL y S3
- **VisualizaciÃ³n**: Apache Superset con dashboards interactivos

## Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AWS EC2 Distributed Cluster                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  EC2-1 (Master)          EC2-2 (Worker1)         EC2-3 (Worker2)â”‚
â”‚  â”œâ”€ Kafka               â”œâ”€ Flink TaskMgr        â”œâ”€ Flink TaskMgrâ”‚
â”‚  â”œâ”€ Zookeeper           â”œâ”€ Spark Worker         â”œâ”€ Spark Worker â”‚
â”‚  â”œâ”€ Flink JobMgr        â”œâ”€ HDFS DataNode        â”œâ”€ HDFS DataNodeâ”‚
â”‚  â”œâ”€ Spark Master        â””â”€ Processing           â””â”€ Processing   â”‚
â”‚  â”œâ”€ HDFS NameNode                                               â”‚
â”‚  â””â”€ Data Producer       EC2-4 (Storage)                         â”‚
â”‚                         â”œâ”€ PostgreSQL                           â”‚
â”‚                         â”œâ”€ Apache Superset                      â”‚
â”‚                         â”œâ”€ HDFS DataNode                        â”‚
â”‚                         â””â”€ S3 Connector                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## CaracterÃ­sticas Principales

### ğŸš€ Deployment Automatizado
- **create-cluster.sh**: Crea 4 EC2 con Security Group en 5 minutos
- **orchestrate-cluster.sh**: Instala todo el software con un comando
- ConfiguraciÃ³n automÃ¡tica de firewall y red
- Genera archivo con IPs y comandos SSH listos

### ğŸ“Š Pipeline Completo
- **Streaming**: Procesamiento en tiempo real con Flink (1-minute windows)
- **Batch**: AnÃ¡lisis histÃ³ricos diarios con Spark
- **Storage**: HDFS distribuido + PostgreSQL + S3
- **Visualization**: Dashboards interactivos con Superset

### ğŸ”§ TecnologÃ­as

- **Streaming**: Apache Kafka 3.6.0, Apache Flink 1.18.0
- **Batch**: Apache Spark 3.5.0
- **Storage**: HDFS 3.3.6, PostgreSQL 15, Amazon S3
- **Visualization**: Apache Superset 3.1.0
- **Infrastructure**: AWS EC2 (Amazon Linux 2023)

## Dataset

- **Fuente**: [NYC Yellow Taxi Trip Data (Kaggle)](https://www.kaggle.com/datasets/elemento/nyc-yellow-taxi-trip-data)
- **Periodo**: 12 meses (2015)
- **TamaÃ±o**: ~40-60 GB
- **Registros**: ~165 millones de viajes

## Estructura del Proyecto

```
bigdata-pipeline/
â”œâ”€â”€ docs/guides/PLAN_ARQUITECTURA.md          # Plan detallado de arquitectura
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ DEPLOYMENT_GUIDE.md       # GuÃ­a de despliegue paso a paso
â”‚   â””â”€â”€ troubleshooting.md
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ common-setup.sh       # Setup comÃºn para todas las EC2
â”‚   â”‚   â”œâ”€â”€ setup-master.sh       # Setup Master node
â”‚   â”‚   â”œâ”€â”€ setup-worker.sh       # Setup Worker nodes
â”‚   â”‚   â”œâ”€â”€ setup-storage.sh      # Setup Storage node
â”‚   â”‚   â””â”€â”€ orchestrate-cluster.sh # OrquestaciÃ³n del cluster
â”‚   â””â”€â”€ configs/                  # Configuraciones de servicios
â”œâ”€â”€ data-producer/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ producer.py           # Data producer principal
â”‚   â”‚   â”œâ”€â”€ kafka_client.py       # Cliente Kafka
â”‚   â”‚   â””â”€â”€ dataset_loader.py     # Cargador de dataset
â”‚   â”œâ”€â”€ config.yaml               # ConfiguraciÃ³n del producer
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ streaming/
â”‚   â”œâ”€â”€ flink-jobs/
â”‚   â”‚   â”œâ”€â”€ src/main/java/com/bigdata/taxi/
â”‚   â”‚   â”‚   â”œâ”€â”€ ZoneAggregationJob.java
â”‚   â”‚   â”‚   â”œâ”€â”€ model/TaxiTrip.java
â”‚   â”‚   â”‚   â””â”€â”€ model/ZoneMetrics.java
â”‚   â”‚   â””â”€â”€ pom.xml
â”‚   â””â”€â”€ build.sh
â”œâ”€â”€ batch/
â”‚   â”œâ”€â”€ spark-jobs/
â”‚   â”‚   â”œâ”€â”€ daily_summary.py      # Job batch diario
â”‚   â”‚   â”œâ”€â”€ hourly_zones.py       # AnÃ¡lisis por hora y zona
â”‚   â”‚   â””â”€â”€ route_analysis.py     # AnÃ¡lisis de rutas
â”‚   â””â”€â”€ schedules/
â””â”€â”€ visualization/
    â”œâ”€â”€ sql/
    â”‚   â””â”€â”€ sample-queries.sql    # Queries para Superset
    â””â”€â”€ superset/
        â””â”€â”€ dashboards/
```

## Quick Start

### OpciÃ³n A: Automatizada (Recomendada) â­

```bash
# 1. Clonar repositorio
git clone https://github.com/fernandoramirez1337/bigdata-pipeline.git
cd bigdata-pipeline/infrastructure/scripts

# 2. Crear 4 EC2 instances automÃ¡ticamente
export KEY_NAME="bigd-key"
export MY_IP="$(curl -s ifconfig.me)/32"
./create-cluster.sh

# 3. Configurar /etc/hosts en todas las instancias
# (Copiar comandos de cluster-info.txt generado)

# 4. Actualizar IPs en orchestrate-cluster.sh
vim orchestrate-cluster.sh
# Actualizar MASTER_IP, WORKER1_IP, WORKER2_IP, STORAGE_IP

# 5. Instalar software (30-45 min)
./orchestrate-cluster.sh setup-all

# 6. Iniciar cluster
./orchestrate-cluster.sh start-cluster
```

**Ver tutorial completo**: [END_TO_END_EXAMPLE.md](docs/guides/END_TO_END_EXAMPLE.md)

### OpciÃ³n B: Manual

Ver detalles en [DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)

### 3. Desplegar Pipeline

```bash
# Crear Kafka topic
./infrastructure/scripts/orchestrate-cluster.sh create-topics

# Iniciar data producer
ssh ec2-user@<MASTER_IP>
cd bigdata-pipeline/data-producer
python3 src/producer.py --config config.yaml

# Desplegar Flink job
cd ../streaming
bash build.sh
flink run flink-jobs/target/taxi-streaming-jobs-1.0-SNAPSHOT.jar

# Configurar Spark batch jobs
crontab -e
# Agregar job diario a las 2 AM
```

### 4. Acceder a Dashboards

- **HDFS**: http://\<MASTER_IP\>:9870
- **Spark**: http://\<MASTER_IP\>:8080
- **Flink**: http://\<MASTER_IP\>:8081
- **Superset**: http://\<STORAGE_IP\>:8088 (admin/admin123)

## AnÃ¡lisis Implementados

### Dashboards en Tiempo Real (Streaming)

1. Viajes por zona/minuto
2. Ingresos totales en tiempo real
3. Top 10 zonas mÃ¡s activas
4. DistribuciÃ³n de mÃ©todos de pago
5. MÃ©tricas promedio (tarifa, distancia, pasajeros)

### Reportes Batch

1. EvoluciÃ³n de viajes diarios
2. AnÃ¡lisis por hora del dÃ­a
3. Patrones por dÃ­a de semana
4. Rutas mÃ¡s frecuentes
5. CorrelaciÃ³n distancia-tarifa
6. Zonas con mayor ingreso

## MÃ©tricas de Rendimiento

- **Throughput**: ~1000 eventos/segundo
- **Latencia de streaming**: <5 segundos
- **Procesamiento batch**: ~10 minutos para 1 dÃ­a de datos
- **Almacenamiento HDFS**: 3x replicaciÃ³n, ~150 GB

## Costos Estimados

### AWS EC2 (us-east-1)
- **Por hora**: ~$0.50
- **Con $50**: ~100 horas de operaciÃ³n
- **Estrategia**: Apagar instancias cuando no se usen

### Storage
- **EBS (550 GB)**: ~$26/mes
- **S3 (60 GB)**: ~$1.40/mes

## Integrantes

- FabiÃ¡n
- Fernando
- Jorge

## DocumentaciÃ³n

### GuÃ­as Principales

- ğŸš€ **[END_TO_END_EXAMPLE.md](docs/guides/END_TO_END_EXAMPLE.md)** - Tutorial completo del zero al dashboard (3-4 horas)
- ğŸ“‹ **[PLAN_ARQUITECTURA.md](docs/guides/PLAN_ARQUITECTURA.md)** - DiseÃ±o completo del sistema (20+ pÃ¡ginas)
- ğŸ“– **[DEPLOYMENT_GUIDE.md](docs/DEPLOYMENT_GUIDE.md)** - InstalaciÃ³n detallada paso a paso
- âš¡ **[QUICK_START_4EC2.md](docs/QUICK_START_4EC2.md)** - Checklist rÃ¡pido de deployment

### Documentos de ImplementaciÃ³n (NUEVO)

- ğŸ“ **[IMPLEMENTATION_LOG.md](docs/IMPLEMENTATION_LOG.md)** - Log detallado de implementaciÃ³n con problemas y soluciones
- âœ… **[CHECKLIST.md](docs/CHECKLIST.md)** - Checklist completo de todas las fases del proyecto

### Recursos TÃ©cnicos

- **[Scripts README](infrastructure/scripts/README.md)** - DocumentaciÃ³n de scripts de infraestructura
- **[Queries SQL](visualization/sql/sample-queries.sql)** - 18+ queries para dashboards de Superset

## Troubleshooting

Ver [Deployment Guide - Troubleshooting](docs/DEPLOYMENT_GUIDE.md#troubleshooting)

## Licencia

MIT License - Proyecto acadÃ©mico

## Referencias

- [NYC TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
- [Apache Flink Documentation](https://flink.apache.org/)
- [Apache Spark Documentation](https://spark.apache.org/)
- [Apache Kafka Documentation](https://kafka.apache.org/)
