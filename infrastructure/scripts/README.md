# Infrastructure Scripts

Scripts for creating and managing the Big Data cluster on AWS.

## Available Scripts

### 1. create-cluster.sh

**Automatically creates 4 EC2 instances with Security Group configured.**

#### Basic Usage

```bash
# With default configuration
./create-cluster.sh

# Or with custom variables
export KEY_NAME="your-key"
export MY_IP="203.0.113.1/32"  # Your IP for SSH
./create-cluster.sh
```

#### Environment Variables

| Variable | Default | Description |
|----------|-------------|-------------|
| `KEY_NAME` | `bigd-key` | Name of your AWS SSH key pair |
| `AMI_ID` | `ami-0453ec754f44f9a4a` | Amazon Linux 2023 (us-east-1) |
| `MY_IP` | `0.0.0.0/0` | Your IP for SSH access (restrict for security) |
| `AWS_REGION` | `us-east-1` | AWS Region |

#### Actions Performed

1. Verifies SSH key exists
2. Retrieves default VPC information
3. Creates Security Group with configured rules
4. Launches 4 EC2 instances:
   - **bigdata-master**: t2.medium, 30 GB
   - **bigdata-worker1**: t2.medium, 50 GB
   - **bigdata-worker2**: t2.medium, 50 GB
   - **bigdata-storage**: t2.medium, 50 GB
5. Generates `cluster-info.txt` with all details

---

### 2. orchestrate-cluster.sh

**Orchestrates the installation and management of the entire cluster.**

#### Available Commands

```bash
# Test connectivity to all instances
./orchestrate-cluster.sh test-connectivity

# Install all software on the 4 EC2 instances (approx. 30-45 min)
./orchestrate-cluster.sh setup-all

# Start all services
./orchestrate-cluster.sh start-cluster

# Stop all services
./orchestrate-cluster.sh stop-cluster

# View service status
./orchestrate-cluster.sh status

# Create Kafka topics
./orchestrate-cluster.sh create-topics

# Deploy Flink and Spark jobs
./orchestrate-cluster.sh deploy-jobs
```

#### Configuration

The script automatically loads IPs from `.cluster-ips` generated by `quick-start.sh`.
Alternatively, you can edit the script to manually set IPs.

---

### 3. common-setup.sh

**Common setup for all instances.**

Installs:
- Java 11
- Python 3 + pip
- Utilities (wget, curl, git, htop, etc.)
- System configurations (limits, swappiness, etc.)

**Usage**: Automatically executed by `setup-*.sh`.

---

### 4. setup-master.sh

**Installs Master node components (EC2-1).**

Installs and configures:
- Apache Zookeeper
- Apache Kafka
- Apache Flink (JobManager)
- Apache Spark (Master)
- Hadoop HDFS (NameNode)

---

### 5. setup-worker.sh

**Installs Worker node components (EC2-2, EC2-3).**

Installs and configures:
- Apache Flink (TaskManager)
- Apache Spark (Worker)
- Hadoop HDFS (DataNode)

---

### 6. setup-storage.sh

**Installs Storage node components (EC2-4).**

Installs and configures:
- PostgreSQL 15
- Apache Superset
- Hadoop HDFS (DataNode)
- AWS CLI v2
- S3 sync scripts

---

## Security Group - Configured Ports

| Port(s) | Protocol | Source | Service |
|-----------|-----------|--------|----------|
| 22 | TCP | Your IP | SSH |
| 2181 | TCP | VPC | Zookeeper |
| 5432 | TCP | VPC | PostgreSQL |
| 6123 | TCP | VPC | Flink RPC |
| 7077 | TCP | VPC | Spark Master |
| 8080-8088 | TCP | 0.0.0.0/0 | Web UIs |
| 9000 | TCP | VPC | HDFS NameNode |
| 9092 | TCP | VPC | Kafka |
| 9870 | TCP | 0.0.0.0/0 | HDFS Web UI |
| All | All | Security Group | Inter-cluster |
