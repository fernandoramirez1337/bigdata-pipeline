# Plan de Arquitectura Big Data - NYC Taxi Pipeline
## AWS Academy Learner Lab - us-east-1

---

## ğŸ“‹ Resumen Ejecutivo

**Objetivo**: Implementar pipeline completo de Big Data para anÃ¡lisis de viajes de taxi NYC con procesamiento batch y streaming distribuido en AWS EC2.

**Dataset**: NYC Yellow Taxi Trip Data (12 meses, ~40-60 GB)
**RegiÃ³n**: us-east-1 (Virginia)
**Presupuesto**: $50 USD por cuenta
**VisualizaciÃ³n**: Apache Superset (open source)

---

## ğŸ—ï¸ Arquitectura Propuesta

### OpciÃ³n A: 4 EC2 (RECOMENDADA para alta disponibilidad)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AWS us-east-1                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ EC2-1: MASTER/COORDINATOR (t3.large - 2 vCPU, 8GB RAM)  â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ Kafka Broker + Zookeeper                               â”‚  â”‚
â”‚  â”‚ â€¢ Flink JobManager                                       â”‚  â”‚
â”‚  â”‚ â€¢ Spark Master                                           â”‚  â”‚
â”‚  â”‚ â€¢ HDFS NameNode                                          â”‚  â”‚
â”‚  â”‚ â€¢ Data Producer (Replay Engine)                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚                              â–¼                â–¼             â–¼   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ EC2-2: WORKER-1    â”‚ â”‚ EC2-3: WORKER-2    â”‚ â”‚ EC2-4:      â”‚ â”‚
â”‚  â”‚ (t3.xlarge)        â”‚ â”‚ (t3.xlarge)        â”‚ â”‚ STORAGE     â”‚ â”‚
â”‚  â”‚ 4 vCPU, 16GB       â”‚ â”‚ 4 vCPU, 16GB       â”‚ â”‚ (t3.large)  â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚ â€¢ Flink TaskMgr    â”‚ â”‚ â€¢ Flink TaskMgr    â”‚ â”‚ â€¢ HDFS DN   â”‚ â”‚
â”‚  â”‚ â€¢ Spark Worker     â”‚ â”‚ â€¢ Spark Worker     â”‚ â”‚ â€¢ PostgreSQLâ”‚ â”‚
â”‚  â”‚ â€¢ HDFS DataNode    â”‚ â”‚ â€¢ HDFS DataNode    â”‚ â”‚ â€¢ Superset  â”‚ â”‚
â”‚  â”‚ â€¢ Kafka Consumer   â”‚ â”‚ â€¢ Kafka Consumer   â”‚ â”‚ â€¢ S3 Sync   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â”‚
â”‚                     â”‚   Amazon S3     â”‚                         â”‚
â”‚                     â”‚ (Batch Results) â”‚                         â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Costo estimado**: ~$2.50-3.00/hora (toda la infraestructura)

### OpciÃ³n B: 3 EC2 (Optimizada para presupuesto)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EC2-1: MASTER        â”‚ â”‚ EC2-2: WORKER        â”‚ â”‚ EC2-3: STORAGE       â”‚
â”‚ (t3.xlarge)          â”‚ â”‚ (t3.xlarge)          â”‚ â”‚ (t3.large)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ Kafka + Zookeeper  â”‚ â”‚ â€¢ Flink TaskMgr      â”‚ â”‚ â€¢ HDFS DataNode      â”‚
â”‚ â€¢ Flink JobManager   â”‚ â”‚ â€¢ Spark Worker       â”‚ â”‚ â€¢ PostgreSQL         â”‚
â”‚ â€¢ Spark Master       â”‚ â”‚ â€¢ HDFS DataNode      â”‚ â”‚ â€¢ Apache Superset    â”‚
â”‚ â€¢ HDFS NameNode      â”‚ â”‚ â€¢ Procesamiento      â”‚ â”‚ â€¢ S3 Connector       â”‚
â”‚ â€¢ Data Producer      â”‚ â”‚ â€¢ Batch + Stream     â”‚ â”‚ â€¢ VisualizaciÃ³n      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Costo estimado**: ~$1.80-2.20/hora

---

## ğŸ”„ Flujo de Datos Completo

### Pipeline de Streaming (Tiempo Real)

```
1. Data Producer (EC2-1)
   â†“
   Reproduce datos histÃ³ricos con timestamps acelerados
   â†“
2. Kafka Topic: "taxi-trips-stream" (EC2-1)
   â†“
   Particiones: 3 (para distribuciÃ³n)
   â†“
3. Apache Flink (EC2-2, EC2-3)
   â†“
   â€¢ Window Operations (1 minuto)
   â€¢ Agregaciones en tiempo real:
     - Viajes por zona/minuto
     - Ingresos totales/minuto
     - Distancia promedio
     - Tipos de pago
   â†“
4. PostgreSQL (EC2-4/Storage)
   â†“
   Tablas actualizadas en tiempo real
   â†“
5. Apache Superset - Dashboard Tiempo Real
```

### Pipeline Batch (Procesamiento HistÃ³rico)

```
1. Kafka Consumer â†’ HDFS Writer (EC2-2, EC2-3)
   â†“
   Escritura continua a HDFS cada hora
   â†“
2. HDFS Storage (Distribuido EC2-2, EC2-3, EC2-4)
   â†“
   Particionado por fecha: /data/taxi/year=2015/month=01/day=01/
   â†“
3. Apache Spark - Batch Jobs (Diario)
   â†“
   â€¢ EvoluciÃ³n de viajes diarios
   â€¢ Promedio de tarifa por zona
   â€¢ AnÃ¡lisis horario (horas pico)
   â€¢ Patrones por dÃ­a de semana
   â€¢ CorrelaciÃ³n distancia-tarifa
   â†“
4. Resultados â†’ S3 + PostgreSQL
   â†“
   â€¢ S3: Archivos Parquet particionados
   â€¢ PostgreSQL: Tablas agregadas
   â†“
5. Apache Superset - Dashboards Batch
```

---

## ğŸ“Š AnÃ¡lisis y MÃ©tricas

### Dashboards en Tiempo Real (Stream Processing)

1. **Actividad en Tiempo Real**
   - Viajes por zona/minuto (mapa de calor)
   - Top 10 zonas mÃ¡s activas
   - Viajes activos en este momento

2. **Ingresos en Tiempo Real**
   - Ingresos totales/minuto
   - Tarifa promedio actual
   - Propinas promedio

3. **Comportamiento de Pasajeros**
   - DistribuciÃ³n de nÃºmero de pasajeros
   - MÃ©todos de pago mÃ¡s usados (Ãºltimos 5 min)
   - Distancia promedio de viajes activos

### Reportes Batch (Procesamiento Diario)

1. **AnÃ¡lisis Temporal**
   - EvoluciÃ³n de viajes por dÃ­a/semana/mes
   - Horas pico de demanda
   - Tendencias por dÃ­a de semana
   - Estacionalidad

2. **AnÃ¡lisis EconÃ³mico**
   - Promedio de ticket por viaje
   - Ingresos totales por zona
   - CorrelaciÃ³n distancia-tarifa
   - AnÃ¡lisis de propinas (% por tipo de pago)

3. **AnÃ¡lisis GeogrÃ¡fico**
   - Rutas mÃ¡s frecuentes (pickup â†’ dropoff)
   - Zonas con mayor ingreso promedio
   - Distancia promedio por zona
   - Mapa de demanda por hora del dÃ­a

4. **AnÃ¡lisis de Eficiencia**
   - DuraciÃ³n promedio de viajes
   - Velocidad promedio por zona/hora
   - OcupaciÃ³n promedio (pasajeros)

---

## ğŸ’¾ Estrategia de Almacenamiento

### Almacenamiento por Capa

| Capa | TecnologÃ­a | UbicaciÃ³n | PropÃ³sito | RetenciÃ³n |
|------|------------|-----------|-----------|-----------|
| **Raw Data** | HDFS | EC2-2,3,4 | Datos originales | 7 dÃ­as |
| **Streaming State** | RocksDB (Flink) | EC2-2,3 | Estado de ventanas | Temporal |
| **Real-time Metrics** | PostgreSQL | EC2-4 | Dashboards RT | 24 horas |
| **Batch Results** | S3 Parquet | S3 Bucket | AnÃ¡lisis histÃ³rico | Permanente |
| **Aggregated Data** | PostgreSQL | EC2-4 | Superset queries | Permanente |

### Esquema de Particionamiento

**HDFS:**
```
/data/taxi/
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ year=2015/
â”‚   â”‚   â”œâ”€â”€ month=01/
â”‚   â”‚   â”‚   â”œâ”€â”€ day=01/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ part-00000.parquet
```

**S3:**
```
s3://bigdata-taxi-pipeline/
â”œâ”€â”€ batch-results/
â”‚   â”œâ”€â”€ daily-summary/year=2015/month=01/
â”‚   â”œâ”€â”€ hourly-zones/year=2015/month=01/
â”‚   â””â”€â”€ route-analysis/year=2015/month=01/
```

**PostgreSQL:**
```sql
-- Streaming metrics
CREATE TABLE real_time_zones (
    zone_id INT,
    window_start TIMESTAMP,
    trip_count INT,
    total_revenue DECIMAL,
    avg_distance DECIMAL,
    PRIMARY KEY (zone_id, window_start)
);

-- Batch aggregations
CREATE TABLE daily_summary (
    date DATE PRIMARY KEY,
    total_trips INT,
    total_revenue DECIMAL,
    avg_fare DECIMAL,
    avg_distance DECIMAL
);
```

---

## ğŸš€ Especificaciones TÃ©cnicas de EC2

### EC2-1: Master/Coordinator

**Instancia**: t3.large (2 vCPU, 8 GB RAM)
**Almacenamiento**: 100 GB gp3
**Componentes**:

```yaml
Kafka:
  version: 3.6.0
  config:
    num.partitions: 3
    replication.factor: 1
    log.retention.hours: 24
    log.segment.bytes: 1GB

Zookeeper:
  version: 3.8.3
  data.dir: /data/zookeeper

Flink JobManager:
  version: 1.18.0
  jobmanager.memory: 2GB

Spark Master:
  version: 3.5.0
  master.memory: 2GB

HDFS NameNode:
  version: 3.3.6
  namenode.memory: 2GB
```

### EC2-2 & EC2-3: Workers (IdÃ©nticos)

**Instancia**: t3.xlarge (4 vCPU, 16 GB RAM)
**Almacenamiento**: 200 GB gp3 cada uno
**Componentes**:

```yaml
Flink TaskManager:
  version: 1.18.0
  taskmanager.memory: 6GB
  taskmanager.numberOfTaskSlots: 4

Spark Worker:
  version: 3.5.0
  worker.memory: 6GB
  worker.cores: 4

HDFS DataNode:
  version: 3.3.6
  datanode.memory: 2GB
  storage: 150GB
```

### EC2-4: Storage/Visualization

**Instancia**: t3.large (2 vCPU, 8 GB RAM)
**Almacenamiento**: 150 GB gp3
**Componentes**:

```yaml
PostgreSQL:
  version: 15
  shared_buffers: 2GB
  max_connections: 100

Apache Superset:
  version: 3.1.0
  workers: 2

HDFS DataNode:
  version: 3.3.6
  storage: 100GB
```

---

## ğŸ’° EstimaciÃ³n de Costos (AWS Academy)

### OpciÃ³n A: 4 EC2

| Recurso | Tipo | Costo/hora | Horas/dÃ­a | Costo/dÃ­a | Costo/30d |
|---------|------|------------|-----------|-----------|-----------|
| EC2-1 Master | t3.large | $0.0832 | 24 | $2.00 | $60.00 |
| EC2-2 Worker | t3.xlarge | $0.1664 | 24 | $4.00 | $120.00 |
| EC2-3 Worker | t3.xlarge | $0.1664 | 24 | $4.00 | $120.00 |
| EC2-4 Storage | t3.large | $0.0832 | 24 | $2.00 | $60.00 |
| EBS (550 GB) | gp3 | - | - | $0.88 | $26.40 |
| S3 (60 GB) | Standard | - | - | $0.05 | $1.40 |
| Transfer OUT | 10 GB | - | - | $0.30 | $9.00 |
| **TOTAL** | | **$0.50** | - | **$13.23** | **$396.80** |

**âš ï¸ Nota**: Con $50 puedes correr el cluster completo por ~3.5 horas (suficiente para demos y pruebas)

### OpciÃ³n B: 3 EC2 (Presupuesto Optimizado)

| Recurso | Tipo | Costo/hora | Costo/dÃ­a | Costo/30d |
|---------|------|------------|-----------|-----------|
| EC2-1 Master | t3.xlarge | $0.1664 | $4.00 | $120.00 |
| EC2-2 Worker | t3.xlarge | $0.1664 | $4.00 | $120.00 |
| EC2-3 Storage | t3.large | $0.0832 | $2.00 | $60.00 |
| EBS + S3 | - | - | $0.93 | $27.80 |
| **TOTAL** | | **$0.42** | **$10.93** | **$327.80** |

**Con $50**: ~5 horas de operaciÃ³n

### Estrategia de OptimizaciÃ³n de Costos

1. **Uso Intermitente**:
   - Levantar cluster solo cuando se necesite
   - Apagar fuera de horario de desarrollo
   - Usar mÃºltiples cuentas de $50

2. **Schedule Sugerido**:
   ```
   Cuenta 1 ($50): ConfiguraciÃ³n + Testing (5 horas)
   Cuenta 2 ($50): Carga de datos + Pipeline batch (5 horas)
   Cuenta 3 ($50): Streaming + Dashboards + Demos (5 horas)
   Total: ~15 horas de operaciÃ³n
   ```

3. **Optimizaciones**:
   - Descargar dataset a una cuenta S3, acceder desde todas
   - Snapshots de EBS con configuraciÃ³n completa
   - Scripts de start/stop automatizados

---

## ğŸ¯ Data Producer - Replay Engine

### CaracterÃ­sticas

```python
Replay Accelerator:
  - Lee datos histÃ³ricos ordenados por timestamp
  - Acelera reproducciÃ³n: 1000x (1 dÃ­a = 86 segundos)
  - Mantiene distribuciÃ³n temporal original
  - Produce a Kafka con rate limiting configurable

ConfiguraciÃ³n:
  - Archivo fuente: s3://datasets/nyc-taxi/2015-*.parquet
  - Rate: 1000 registros/segundo
  - Modo: continuo (loop) o Ãºnico (one-shot)
  - Jitter: Â±10% para simular variabilidad real
```

### Campos Dataset NYC Taxi

```python
Schema:
  - VendorID: int
  - tpep_pickup_datetime: timestamp
  - tpep_dropoff_datetime: timestamp
  - passenger_count: int
  - trip_distance: float
  - pickup_longitude: float
  - pickup_latitude: float
  - RatecodeID: int
  - store_and_fwd_flag: string
  - dropoff_longitude: float
  - dropoff_latitude: float
  - payment_type: int (1=Credit, 2=Cash, 3=No charge, 4=Dispute)
  - fare_amount: float
  - extra: float
  - mta_tax: float
  - tip_amount: float
  - tolls_amount: float
  - total_amount: float
```

---

## ğŸ“ˆ Jobs de Procesamiento

### Flink Streaming Job

**Ventanas de AgregaciÃ³n**:

```java
// 1. Viajes por zona cada minuto
TripStream
  .keyBy(trip -> getPickupZone(trip.pickup_lat, trip.pickup_lon))
  .window(TumblingProcessingTimeWindows.of(Time.minutes(1)))
  .aggregate(new TripCountAggregator())
  .addSink(new PostgreSQLSink("real_time_zones"));

// 2. Ingresos en tiempo real
TripStream
  .windowAll(SlidingProcessingTimeWindows.of(Time.minutes(5), Time.seconds(30)))
  .aggregate(new RevenueAggregator())
  .addSink(new PostgreSQLSink("real_time_revenue"));

// 3. Top zonas activas
TripStream
  .keyBy(trip -> getPickupZone(...))
  .window(TumblingProcessingTimeWindows.of(Time.minutes(5)))
  .aggregate(new ZoneActivityAggregator())
  .windowAll(TumblingProcessingTimeWindows.of(Time.minutes(5)))
  .process(new TopNZones(10))
  .addSink(new PostgreSQLSink("top_zones"));
```

### Spark Batch Jobs

**Job 1: Daily Summary**
```scala
// Ejecuta diariamente a las 2 AM
spark.read.parquet("hdfs:///data/taxi/year=*/month=*/day=*/")
  .filter($"tpep_pickup_datetime".cast("date") === current_date - 1)
  .groupBy($"tpep_pickup_datetime".cast("date").as("date"))
  .agg(
    count("*").as("total_trips"),
    sum("total_amount").as("total_revenue"),
    avg("fare_amount").as("avg_fare"),
    avg("trip_distance").as("avg_distance")
  )
  .write.mode("append")
  .parquet("s3://bucket/batch-results/daily-summary/")
```

**Job 2: Hourly Zone Analysis**
```scala
// AnÃ¡lisis por zona y hora
spark.read.parquet("hdfs:///data/taxi/")
  .withColumn("hour", hour($"tpep_pickup_datetime"))
  .withColumn("zone", getZoneUDF($"pickup_latitude", $"pickup_longitude"))
  .groupBy("zone", "hour")
  .agg(
    count("*").as("trip_count"),
    avg("total_amount").as("avg_revenue"),
    avg("trip_distance").as("avg_distance")
  )
  .write.partitionBy("zone")
  .parquet("s3://bucket/batch-results/hourly-zones/")
```

**Job 3: Route Analysis**
```scala
// Rutas mÃ¡s frecuentes
spark.read.parquet("hdfs:///data/taxi/")
  .withColumn("pickup_zone", getZoneUDF($"pickup_latitude", $"pickup_longitude"))
  .withColumn("dropoff_zone", getZoneUDF($"dropoff_latitude", $"dropoff_longitude"))
  .groupBy("pickup_zone", "dropoff_zone")
  .agg(
    count("*").as("route_count"),
    avg("total_amount").as("avg_fare"),
    avg("trip_distance").as("avg_distance"),
    avg("duration_minutes").as("avg_duration")
  )
  .orderBy(desc("route_count"))
  .limit(1000)
  .write.parquet("s3://bucket/batch-results/route-analysis/")
```

---

## ğŸ¨ Apache Superset - Dashboards

### Dashboard 1: Tiempo Real (Stream)

**GrÃ¡ficos**:

1. **Big Number - Viajes Activos**
   - Query: `SELECT SUM(trip_count) FROM real_time_zones WHERE window_start > NOW() - INTERVAL '1 minute'`

2. **Line Chart - Viajes/Minuto (Ãºltimos 30 min)**
   - X: window_start
   - Y: trip_count
   - Refresh: 10 segundos

3. **Map - Zonas Activas**
   - Heatmap de viajes por zona
   - Datos Ãºltimos 5 minutos

4. **Bar Chart - Top 10 Zonas**
   - Zonas con mÃ¡s viajes en tiempo real

5. **Pie Chart - MÃ©todos de Pago**
   - DistribuciÃ³n Ãºltimos 5 minutos

### Dashboard 2: AnÃ¡lisis HistÃ³rico (Batch)

**GrÃ¡ficos**:

1. **Line Chart - EvoluciÃ³n Diaria**
   - Serie temporal de viajes por dÃ­a
   - Filtros por rango de fechas

2. **Heatmap - Demanda por Hora/DÃ­a**
   - Rows: DÃ­a de semana
   - Cols: Hora del dÃ­a
   - Color: NÃºmero de viajes

3. **Sankey Diagram - Rutas Principales**
   - Origen â†’ Destino
   - Grosor: Frecuencia

4. **Box Plot - DistribuciÃ³n de Tarifas**
   - Por zona / hora del dÃ­a

5. **Scatter Plot - Distancia vs Tarifa**
   - CorrelaciÃ³n y outliers

---

## ğŸ“¦ Estructura del Proyecto

```
bigdata-pipeline/
â”œâ”€â”€ README.md
â”œâ”€â”€ PLAN_ARQUITECTURA.md (este archivo)
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ deployment-guide.md
â”‚   â”œâ”€â”€ troubleshooting.md
â”‚   â””â”€â”€ cost-optimization.md
â”œâ”€â”€ infrastructure/
â”‚   â”œâ”€â”€ terraform/                    # IaC (opcional)
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”œâ”€â”€ ec2.tf
â”‚   â”‚   â””â”€â”€ security-groups.tf
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ setup-master.sh          # Setup EC2-1
â”‚   â”‚   â”œâ”€â”€ setup-worker.sh          # Setup EC2-2,3
â”‚   â”‚   â”œâ”€â”€ setup-storage.sh         # Setup EC2-4
â”‚   â”‚   â”œâ”€â”€ start-cluster.sh
â”‚   â”‚   â””â”€â”€ stop-cluster.sh
â”‚   â””â”€â”€ configs/
â”‚       â”œâ”€â”€ kafka/
â”‚       â”‚   â””â”€â”€ server.properties
â”‚       â”œâ”€â”€ flink/
â”‚       â”‚   â”œâ”€â”€ flink-conf.yaml
â”‚       â”‚   â””â”€â”€ masters
â”‚       â”œâ”€â”€ spark/
â”‚       â”‚   â””â”€â”€ spark-defaults.conf
â”‚       â””â”€â”€ hdfs/
â”‚           â”œâ”€â”€ core-site.xml
â”‚           â””â”€â”€ hdfs-site.xml
â”œâ”€â”€ data-producer/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ producer.py              # Main replay engine
â”‚   â”‚   â”œâ”€â”€ kafka_client.py
â”‚   â”‚   â””â”€â”€ dataset_loader.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ streaming/
â”‚   â”œâ”€â”€ flink-jobs/
â”‚   â”‚   â”œâ”€â”€ pom.xml
â”‚   â”‚   â””â”€â”€ src/main/java/
â”‚   â”‚       â”œâ”€â”€ ZoneAggregationJob.java
â”‚   â”‚       â”œâ”€â”€ RevenueAggregationJob.java
â”‚   â”‚       â””â”€â”€ TopZonesJob.java
â”‚   â””â”€â”€ build.sh
â”œâ”€â”€ batch/
â”‚   â”œâ”€â”€ spark-jobs/
â”‚   â”‚   â”œâ”€â”€ daily_summary.py
â”‚   â”‚   â”œâ”€â”€ hourly_zones.py
â”‚   â”‚   â”œâ”€â”€ route_analysis.py
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â””â”€â”€ zone_mapping.py
â”‚   â””â”€â”€ schedules/
â”‚       â””â”€â”€ cron-jobs.txt
â”œâ”€â”€ visualization/
â”‚   â”œâ”€â”€ superset/
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â”‚   â”œâ”€â”€ realtime-dashboard.json
â”‚   â”‚   â”‚   â””â”€â”€ batch-dashboard.json
â”‚   â”‚   â””â”€â”€ setup.sh
â”‚   â””â”€â”€ sql/
â”‚       â”œâ”€â”€ create-tables.sql
â”‚       â””â”€â”€ sample-queries.sql
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ performance/
â””â”€â”€ monitoring/
    â”œâ”€â”€ prometheus/
    â”‚   â””â”€â”€ prometheus.yml
    â””â”€â”€ grafana/
        â””â”€â”€ dashboards/
```

---

## ğŸ”§ PrÃ³ximos Pasos

1. **Confirmar Arquitectura**: Â¿3 o 4 EC2?
2. **Crear Scripts de Setup Automatizados**
3. **Implementar Data Producer**
4. **Configurar Flink Streaming Jobs**
5. **Implementar Spark Batch Jobs**
6. **Configurar PostgreSQL + Superset**
7. **Testing y OptimizaciÃ³n**
8. **DocumentaciÃ³n Final**

---

## â“ Preguntas Pendientes

1. Â¿Confirmas 4 EC2 o prefieres optimizar a 3?
2. Â¿Tienes ya las cuentas de AWS Academy configuradas?
3. Â¿Prefieres que genere todos los scripts ahora o paso a paso?
4. Â¿Alguna mÃ©trica especÃ­fica adicional que quieras en los dashboards?
