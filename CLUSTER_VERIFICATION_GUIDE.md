# Gu√≠a de Verificaci√≥n del Cluster

## Scripts de Verificaci√≥n Disponibles

Hemos creado dos scripts completos para verificar la correcta distribuci√≥n y conexi√≥n entre los nodos del cluster:

### 1. üé® `cluster-dashboard.sh` - Dashboard Visual

**Prop√≥sito**: Vista r√°pida y visual del estado del cluster

**Uso**:
```bash
./infrastructure/scripts/cluster-dashboard.sh
```

**Qu√© muestra**:
- ‚úÖ Topolog√≠a del cluster (diagrama ASCII)
- ‚úÖ Estado de conectividad de cada nodo
- ‚úÖ Estado de todos los servicios (Java processes)
- ‚úÖ Estado del cluster HDFS (NameNode + DataNodes)
- ‚úÖ Estado del cluster Spark (Master + Workers)
- ‚úÖ Estado del cluster Flink (JobManager + TaskManagers)
- ‚úÖ Estado de Kafka y Zookeeper (con lista de topics)
- ‚úÖ Estado de PostgreSQL (con lista de databases)
- ‚úÖ URLs de todas las Web UIs

**Tiempo de ejecuci√≥n**: ~10 segundos

**Ideal para**:
- Verificaci√≥n r√°pida del estado general
- Monitoreo diario
- Demostraci√≥n del cluster

---

### 2. üîç `verify-cluster-health.sh` - Verificaci√≥n Completa

**Prop√≥sito**: Diagn√≥stico exhaustivo de conectividad y comunicaci√≥n

**Uso**:
```bash
./infrastructure/scripts/verify-cluster-health.sh
```

**Qu√© verifica** (10 categor√≠as de tests):

#### TEST 1: SSH Connectivity
- Verifica que se puede conectar por SSH a los 4 nodos

#### TEST 2: Internal Network Connectivity
- Prueba ping entre todos los nodos usando IPs privadas
- Master ‚Üí Workers/Storage
- Workers ‚Üí Master/otros Workers/Storage

#### TEST 3: Hostname Resolution
- Verifica que `/etc/hosts` est√° correctamente configurado
- Prueba resoluci√≥n de hostnames (master-node, worker1-node, etc.)

#### TEST 4: Java Processes (jps)
- Verifica que todos los procesos Java est√°n corriendo
- Master: NameNode, Kafka, Zookeeper, Spark Master, Flink JobManager
- Workers: DataNode, Spark Worker, Flink TaskManager
- Storage: DataNode, PostgreSQL

#### TEST 5: HDFS Cluster Status
- Verifica que NameNode est√° activo
- Cuenta DataNodes conectados (debe ser 3)
- Verifica que cada DataNode est√° registrado

#### TEST 6: HDFS Port Connectivity
- Prueba conectividad TCP a puerto 9000 desde cada DataNode
- Verifica que NameNode est√° escuchando en `0.0.0.0:9000` (no `127.0.0.1`)

#### TEST 7: Spark Cluster Status
- Consulta Spark Master Web UI
- Verifica cantidad de Workers conectados (debe ser 2)
- Prueba conectividad TCP a puerto 7077

#### TEST 8: Flink Cluster Status
- Consulta Flink JobManager API REST
- Verifica cantidad de TaskManagers conectados (debe ser 2)
- Prueba conectividad TCP a puerto 6123

#### TEST 9: Kafka & Zookeeper Status
- Verifica que Zookeeper responde (`echo stat | nc localhost 2181`)
- Verifica que Kafka responde y cuenta topics

#### TEST 10: PostgreSQL Status
- Prueba conexi√≥n a PostgreSQL
- Verifica que databases `superset` y `taxi_analytics` existen

**Salida**:
```
TEST SUMMARY
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
Total Tests:    85
Passed:         82 ‚úÖ
Failed:         0 ‚ùå
Warnings:       3 ‚ö†Ô∏è

üéâ CLUSTER HEALTH: EXCELLENT
All nodes are connected and communicating correctly!
```

**Tiempo de ejecuci√≥n**: ~30-45 segundos

**Ideal para**:
- Troubleshooting de problemas
- Verificaci√≥n despu√©s de cambios de configuraci√≥n
- Validaci√≥n despu√©s de reiniciar servicios
- Diagn√≥stico de problemas de red

---

## Comparaci√≥n de Scripts

| Caracter√≠stica | cluster-dashboard.sh | verify-cluster-health.sh |
|----------------|---------------------|-------------------------|
| **Velocidad** | ‚ö° R√°pido (~10s) | üîç Completo (~40s) |
| **Prop√≥sito** | Vista general | Diagn√≥stico profundo |
| **Output** | Visual/Dashboard | Tests detallados |
| **Tests** | Estado de servicios | Conectividad + Servicios |
| **Uso diario** | ‚úÖ Ideal | Solo cuando hay problemas |
| **Debugging** | ‚ùå Limitado | ‚úÖ Exhaustivo |

---

## Casos de Uso Comunes

### Caso 1: Verificaci√≥n Matutina
```bash
# Dashboard r√°pido para ver que todo est√° bien
./infrastructure/scripts/cluster-dashboard.sh
```

### Caso 2: Despu√©s de Reiniciar Servicios
```bash
# Verificaci√≥n completa para asegurar que todo se reconect√≥
./infrastructure/scripts/verify-cluster-health.sh
```

### Caso 3: Troubleshooting de DataNodes
```bash
# Si HDFS muestra problemas, ejecutar verificaci√≥n completa
./infrastructure/scripts/verify-cluster-health.sh

# Revisar espec√≠ficamente TEST 5 y TEST 6
# Si falla TEST 6, hay problema de conectividad de red
```

### Caso 4: Despu√©s de Cambios de Configuraci√≥n
```bash
# Verificar que los cambios no rompieron nada
./infrastructure/scripts/verify-cluster-health.sh

# Si hay fallos, revisar logs espec√≠ficos:
# - HDFS: /var/log/bigdata/hadoop/
# - Kafka: /var/log/bigdata/kafka.log
# - Otros: journalctl -u <service>
```

### Caso 5: Antes de Procesar Datos Cr√≠ticos
```bash
# Asegurar que el cluster est√° 100% saludable
./infrastructure/scripts/verify-cluster-health.sh

# Solo proceder si sale: "CLUSTER HEALTH: EXCELLENT"
```

---

## Interpretando Resultados

### Estados Posibles

#### ‚úÖ EXCELLENT (Verde)
- Todos los tests pasaron
- Sin warnings
- Cluster 100% operacional
- **Acci√≥n**: Ninguna

#### ‚ö†Ô∏è GOOD (Amarillo)
- Todos los tests pasaron
- Algunos warnings
- Cluster funcional pero con componentes opcionales apagados
- **Acci√≥n**: Revisar warnings, no cr√≠tico

#### ‚ùå ISSUES DETECTED (Rojo)
- Algunos tests fallaron
- Cluster no est√° completamente operacional
- **Acci√≥n**: Revisar tests fallidos y corregir

---

## Qu√© Hacer si Hay Fallos

### Fallo en TEST 1 (SSH Connectivity)
```bash
# Problema: No se puede conectar por SSH
# Soluci√≥n: Verificar que instancias EC2 est√°n running
aws ec2 describe-instances --instance-ids <instance-id>
```

### Fallo en TEST 2 (Network Connectivity)
```bash
# Problema: Nodos no pueden hacer ping entre s√≠
# Soluci√≥n 1: Verificar Security Groups de AWS
# Soluci√≥n 2: Verificar que /etc/hosts est√° correcto
ssh -i ~/.ssh/bigd-key.pem ec2-user@<node-ip> "cat /etc/hosts"
```

### Fallo en TEST 5 (HDFS Cluster)
```bash
# Problema: DataNodes no est√°n conectados
# Verificar logs de DataNodes:
ssh -i ~/.ssh/bigd-key.pem ec2-user@<worker-ip>
tail -100 /var/log/bigdata/hadoop/hadoop-*-datanode-*.log

# Soluci√≥n com√∫n: Reiniciar DataNodes
ssh -i ~/.ssh/bigd-key.pem ec2-user@<worker-ip>
source /etc/profile.d/bigdata.sh
$HADOOP_HOME/bin/hdfs --daemon stop datanode
$HADOOP_HOME/bin/hdfs --daemon start datanode
```

### Fallo en TEST 6 (HDFS Port Connectivity)
```bash
# Problema: Puerto 9000 no es accesible
# Diagn√≥stico 1: Verificar que NameNode est√° escuchando en 0.0.0.0
ssh -i ~/.ssh/bigd-key.pem ec2-user@44.210.18.254
sudo netstat -tulnp | grep 9000

# Si muestra 127.0.0.1:9000 (MAL):
./infrastructure/scripts/fix-namenode-binding.sh

# Diagn√≥stico 2: Verificar AWS Security Groups
# Ver: docs/AWS_SECURITY_GROUP_FIX.md
```

### Fallo en TEST 7/8 (Spark/Flink)
```bash
# Problema: Workers/TaskManagers no conectados
# Soluci√≥n: Reiniciar servicios en orden

# Spark:
ssh -i ~/.ssh/bigd-key.pem ec2-user@44.210.18.254
source /etc/profile.d/bigdata.sh
$SPARK_HOME/sbin/stop-worker.sh
$SPARK_HOME/sbin/start-worker.sh spark://master-node:7077

# Flink:
ssh -i ~/.ssh/bigd-key.pem ec2-user@<worker-ip>
source /etc/profile.d/bigdata.sh
$FLINK_HOME/bin/taskmanager.sh stop
$FLINK_HOME/bin/taskmanager.sh start
```

---

## Automatizaci√≥n (Opcional)

### Cron Job para Monitoreo Diario

```bash
# Agregar a crontab en tu m√°quina local
# Ejecuta el dashboard cada d√≠a a las 9 AM
0 9 * * * /path/to/bigdata-pipeline/infrastructure/scripts/cluster-dashboard.sh > /tmp/cluster-status.log 2>&1

# Si quieres recibir email cuando hay fallos:
0 9 * * * /path/to/bigdata-pipeline/infrastructure/scripts/verify-cluster-health.sh || mail -s "Cluster Health Issues" your@email.com < /tmp/cluster-status.log
```

### Script de Alerta

```bash
#!/bin/bash
# check-and-alert.sh

./infrastructure/scripts/verify-cluster-health.sh
EXIT_CODE=$?

if [ $EXIT_CODE -ne 0 ]; then
    echo "Cluster health check failed!" | mail -s "ALERT: Cluster Issues Detected" admin@example.com

    # Opcional: Reiniciar servicios autom√°ticamente
    # ./infrastructure/scripts/restart-all-services.sh
fi
```

---

## M√©tricas de Salud del Cluster

### Cluster Saludable (Expected)
```
‚úÖ SSH Connectivity:         4/4 nodes
‚úÖ Network Connectivity:    12/12 paths
‚úÖ Hostname Resolution:      6/6 hosts
‚úÖ Java Processes:          12/12 services
‚úÖ HDFS DataNodes:           3/3 connected
‚úÖ HDFS Port Connectivity:   3/3 reachable
‚úÖ Spark Workers:            2/2 connected
‚úÖ Flink TaskManagers:       2/2 connected
‚úÖ Kafka/Zookeeper:          2/2 running
‚úÖ PostgreSQL:               1/1 running
```

### Signos de Problemas

| S√≠ntoma | Causa Probable | Severidad |
|---------|---------------|-----------|
| DataNodes: 0/3 | NameNode binding o red | üî¥ Cr√≠tico |
| DataNodes: 1-2/3 | Worker espec√≠fico apagado | üü° Medio |
| Spark Workers: 0-1/2 | Spark Worker apagado | üü° Medio |
| Kafka no responde | Zookeeper apagado | üî¥ Cr√≠tico |
| PostgreSQL no responde | Servicio apagado | üü° Medio |

---

## Logs de Diagn√≥stico

Si los scripts reportan problemas, revisar estos logs:

```bash
# HDFS
/var/log/bigdata/hadoop/hadoop-*-namenode-*.log
/var/log/bigdata/hadoop/hadoop-*-datanode-*.log

# Kafka
/var/log/bigdata/kafka.log

# Zookeeper
/var/log/bigdata/zookeeper/zookeeper.log

# Spark
/opt/bigdata/spark/logs/

# Flink
/opt/bigdata/flink/log/

# PostgreSQL
/var/log/postgresql/
sudo journalctl -u postgresql

# Superset
/var/log/bigdata/superset.log
```

---

## Referencias

- **Documentaci√≥n completa**: `docs/PROBLEMS_FIXED.md`
- **Fix de HDFS**: `docs/HDFS_NAMENODE_BINDING_FIX.md`
- **Security Groups**: `docs/AWS_SECURITY_GROUP_FIX.md`
- **Quick Start**: `QUICK_START.md`

---

**√öltima actualizaci√≥n**: 20 de Noviembre 2025
**Mantenedor**: DevOps Team
**Versi√≥n**: 1.0
